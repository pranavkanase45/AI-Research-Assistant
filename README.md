# ðŸ¤– AI Research Assistant with Multi-Agent Collaboration

An AI-powered **Multi-Agent Research Assistant** built with **Generative AI, Agentic AI, LangGraph, RAG, Persistent Memory, FAISS, and FastAPI**. It supports multi-format uploads, intelligent PDF analysis, and expert-like Q&A via Researcher, Summarizer, Critic, and Editor agents - offering deep, contextual, and interactive research insights.

This **Multi-Agent architecture** (Researcher, Summarizer, Critic, and Editor) simulates how real researchers process information. It integrates **FastAPI (backend), Next.js + TailwindCSS (frontend), FAISS (vector search), and SQLite** for conversation persistence.

---

## ðŸš€ Features

- ðŸ§  **Multi-Agent Workflow**
  - **Research Agent â†’** Finds relevant chunks using FAISS
  - **Summarizer Agent â†’** Creates concise summaries
  - **Critic Agent â†’** Identifies limitations and gaps
  - **Editor Agent â†’** Refines and formats final responses
- **ðŸ“š Multi-Document Support** â†’ Upload and query multiple PDFs, DOCX, or TXT files
- **ðŸ’¬ Conversation Memory** â†’ SQLite-backed memory for contextual, follow-up queries
- **ðŸ§© Chunking & Embeddings** â†’ Splits documents into chunks and embeds them using OpenAI models
- **âš¡ FAISS Vector Search** â†’ High-speed semantic retrieval of embedded text chunks
- **ðŸ”„ LangGraph Orchestration** â†’ Structured multi-agent pipeline with conditional routing
- **ðŸŽ¨ Modern UI** â†’ Responsive frontend built with Next.js and TailwindCSS

---

## ðŸ—ï¸ Project Structure

```
AI-Research-Assistant/
â”œâ”€â”€ backend/                           # FastAPI Backend
â”‚   â”œâ”€â”€ agents/                        # Multi-Agent System
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent_state.py            # Shared state for LangGraph
â”‚   â”‚   â”œâ”€â”€ critic_agent.py           # Validates response quality
â”‚   â”‚   â”œâ”€â”€ editor_agent.py           # Refines final output
â”‚   â”‚   â”œâ”€â”€ langgraph_nodes.py        # LangGraph node definitions
â”‚   â”‚   â”œâ”€â”€ langgraph_workflow.py     # Workflow graph construction
â”‚   â”‚   â”œâ”€â”€ orchestrator.py           # Main workflow orchestrator
â”‚   â”‚   â”œâ”€â”€ research_agent.py         # Document retrieval agent
â”‚   â”‚   â””â”€â”€ summarizer_agent.py       # Summarization agent
â”‚   â”‚
â”‚   â”œâ”€â”€ db/                            # Database & Storage
â”‚   â”‚   â”œâ”€â”€ conversation_memory.py    # Legacy memory (deprecated)
â”‚   â”‚   â”œâ”€â”€ conversations.db          # SQLite database
â”‚   â”‚   â”œâ”€â”€ faiss_index.bin           # FAISS vector index
â”‚   â”‚   â”œâ”€â”€ faiss_index_documents.pkl # Document metadata
â”‚   â”‚   â”œâ”€â”€ faiss_index_meta.pkl      # Chunk metadata
â”‚   â”‚   â”œâ”€â”€ faiss_store.py            # FAISS operations
â”‚   â”‚   â”œâ”€â”€ memory_store.py           # Legacy memory store
â”‚   â”‚   â”œâ”€â”€ multi_doc_store.py        # Multi-document FAISS manager
â”‚   â”‚   â”œâ”€â”€ sqlite_memory.py          # SQLite conversation memory
â”‚   â”‚   â””â”€â”€ documents/                # Per-document FAISS indexes
â”‚   â”‚       â””â”€â”€ [doc_name]/           # Individual document stores
â”‚   â”‚           â”œâ”€â”€ index.bin
â”‚   â”‚           â”œâ”€â”€ metadata.pkl
â”‚   â”‚           â””â”€â”€ info.pkl
â”‚   â”‚
â”‚   â”œâ”€â”€ logs/                          # Application Logs
â”‚   â”‚   â”œâ”€â”€ agents.log                # Agent workflow logs
â”‚   â”‚   â”œâ”€â”€ api.log                   # API request logs
â”‚   â”‚   â”œâ”€â”€ database.log              # Database operation logs
â”‚   â”‚   â””â”€â”€ parser.log                # Document parsing logs
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                        # Data Models
â”‚   â”‚   â””â”€â”€ schemas.py                # Pydantic request/response schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                         # Utility Modules
â”‚   â”‚   â”œâ”€â”€ document_parser.py        # Multi-format document parser
â”‚   â”‚   â”œâ”€â”€ embeddings.py             # OpenAI embedding generation
â”‚   â”‚   â”œâ”€â”€ logger.py                 # Logging configuration
â”‚   â”‚   â””â”€â”€ pdf_parser.py             # Legacy PDF parser
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py                      # Configuration loader
â”‚   â”œâ”€â”€ main.py                        # FastAPI application & routes
â”‚   â””â”€â”€ requirements.txt               # Python dependencies
â”‚
â”œâ”€â”€ frontend/                          # Next.js Frontend
â”‚   â”œâ”€â”€ components/                    # React Components
â”‚   â”‚   â”œâ”€â”€ AgentGraph.tsx            # Workflow visualization
â”‚   â”‚   â””â”€â”€ ChatBox.tsx               # Chat interface
â”‚   â”‚
â”‚   â”œâ”€â”€ pages/                         # Next.js Pages
â”‚   â”‚   â”œâ”€â”€ _app.tsx                  # App wrapper with providers
â”‚   â”‚   â”œâ”€â”€ index.tsx                 # Main chat interface
â”‚   â”‚   â””â”€â”€ history.tsx               # Conversation history view
â”‚   â”‚
â”‚   â”œâ”€â”€ styles/                        # Stylesheets
â”‚   â”‚   â””â”€â”€ globals.css               # Global TailwindCSS styles
â”‚   â”‚
â”‚   â”œâ”€â”€ next-env.d.ts                 # Next.js TypeScript declarations
â”‚   â”œâ”€â”€ package.json                  # Node dependencies
â”‚   â”œâ”€â”€ package-lock.json             # Lockfile
â”‚   â”œâ”€â”€ postcss.config.js             # PostCSS configuration
â”‚   â”œâ”€â”€ tailwind.config.js            # TailwindCSS configuration
â”‚   â””â”€â”€ tsconfig.json                 # TypeScript configuration
â”‚
â”œâ”€â”€ venv/                              # Python Virtual Environment
â”‚
â”œâ”€â”€ .env                               # Environment variables (gitignored)
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”œâ”€â”€ PROJECT_ANALYSIS.md                # Project documentation
â””â”€â”€ README.md                          # This file
```
---

## âš™ï¸ Tech Stack

### ðŸ–¥ï¸ Backend
- **FastAPI**: High-performance async API framework
- **PDFPlumber**: PDF text extraction
- **Python-DOCX**: DOCX parsing
- **BeautifulSoup4**: HTML parsing

### ðŸŽ¨ Frontend
- **Next.js 15**: React framework with App Router
- **TypeScript**: Type-safe development
- **TailwindCSS 4**: Utility-first styling
- **React Query (TanStack)**: Data fetching and caching
- **Radix UI**: Accessible component primitives
- **Axios**: HTTP client

### ðŸ—„ï¸ Databases
- **FAISS**: Vector similarity search (CPU)
- **SQLite**: Conversation memory persistence

### ðŸ¤– AI 
- **LangGraph**: Agent workflow orchestration
- **OpenAI**: GPT-4o-mini and text-embedding-3-small models

---

## ðŸ”§ Prerequisites

- Python 3.8+
- Node.js 18+
- OpenAI API Key
  
---

## âš¡ Installation

### 2ï¸âƒ£ Backend Setup

```bash
# Create and activate virtual environment
python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows

# Install dependencies
cd backend
pip install -r requirements.txt
# Run Server
uvicorn main:app --reload --port 8000
```

### 3ï¸âƒ£ Environment Configuration

Create a `.env` file in the root directory:

```env
OPENAI_API_KEY=your_openai_api_key
VECTOR_DB_PATH=./backend/db/documents
EMBEDDING_MODEL=text-embedding-3-small
LLM_MODEL=gpt-4o-mini
BACKEND_PORT=8000
```

### 4ï¸âƒ£ Frontend Setup

```bash
cd frontend
npm install
npm run dev
```
---

## ðŸ§© API Endpoints

### Document Management
- `POST /upload` - Upload document (legacy, single FAISS index)
- `POST /upload-v2` - Upload document (multi-doc, separate indexes)
- `GET /documents` - List all uploaded documents

### Query Endpoints
- `POST /ask` - Simple RAG query (legacy)
- `POST /ask-agents` - Multi-agent workflow query (single FAISS index)
- `POST /ask-v2` - Multi-document query with context switching

### Session Management
- `POST /sessions/create` - Create new conversation session
- `GET /sessions/{session_id}/history` - Get session history
- `DELETE /sessions/{session_id}` - Clear session
- `GET /sessions` - List all sessions

### Utilities
- `GET /health` - Health check
- `GET /workflow/diagram` - Get LangGraph workflow as Mermaid diagram
- `GET /stats` - Database statistics

---

## ðŸ§  Multi-Agent Workflow

The system uses a sophisticated multi-agent pipeline:

1. **Research Agent**: Searches documents using FAISS similarity search
2. **Summarizer Agent**: Condenses retrieved information
3. **Critic Agent**: Evaluates quality and completeness
4. **Editor Agent**: Produces final polished response

Agents communicate through a shared state managed by LangGraph, with conditional routing based on response quality.

---

## ðŸ§¾ Document Processing

Supported formats:
- **PDF**: Extracted using PDFPlumber
- **DOCX**: Parsed with python-docx
- **HTML**: Cleaned with BeautifulSoup4
- **TXT**: Direct text reading

Documents are:
1. Chunked into ~500 character segments
2. Embedded using OpenAI's text-embedding-3-small
3. Stored in FAISS vector indexes
4. Retrieved via semantic similarity search

---

## ðŸ’¬ Conversation Memory

- **Session-based**: Each conversation has a unique session ID
- **SQLite storage**: Persistent chat history
- **Context retention**: Previous messages inform agent responses
- **Metadata tracking**: Sources and workflow logs stored per message

## Development

### Backend Structure

```python
# Example: Adding a new agent
from agents.base import BaseAgent

class NewAgent(BaseAgent):
    def process(self, state):
        # Agent logic here
        return updated_state
```

### Frontend Structure

```tsx
// Example: API call with React Query
const { data } = useQuery({
  queryKey: ['documents'],
  queryFn: async () => {
    const res = await axios.get('documents')
    return res.data
  }
})
```
---

## ðŸ“œ Logging

Comprehensive logging across:
- API requests (`backend/logs/api.log`)
- Agent workflows (`backend/logs/agents.log`)
- Document parsing (`backend/logs/parser.log`)
- Database operations (`backend/logs/database.log`)
  
---

## ðŸŒŸ Future Scope

- LangSmith integration for agent evaluation
- Audio/video research input (Whisper API)
- Multi-language summarization
- Graph visualization of LangGraph workflow
- PDF/Word export for AI-generated reports
  
---

## ðŸªª License

**MIT License** â€“ Free to use and modify.

---

